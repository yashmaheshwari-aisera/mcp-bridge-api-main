This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-04-20T05:28:07.563Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
llm_test.py
mcp-bridge.js
README.md

================================================================
Repository Files
================================================================

================
File: llm_test.py
================
#!/usr/bin/env python3
"""
MCP-Gemini Agent - Integrating MCP with Gemini LLM

This script creates an agent that connects to MCP Bridge and uses Google's Gemini LLM
to process user requests and execute MCP tools commands. It supports multi-step reasoning
with the ability to make multiple API calls in sequence when needed.

This version supports:
1. Security confirmation flow for medium and high risk operations
2. Sequential tool calls for complex operations
3. Automatic discovery of allowed directories for file operations
4. Optional JSON result display control
5. Configurable MCP Bridge URL and port
"""

import os
import json
import requests
import argparse
from datetime import datetime
import google.generativeai as genai
from google.generativeai import GenerativeModel
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from rich.prompt import Confirm
from rich.syntax import Syntax

# Default configuration
DEFAULT_MCP_BRIDGE_URL = "http://localhost:3000"  # Default URL for MCP Bridge
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "AIzaSyCXQVBU7rx_KujKye40bVa84XjAbVFr7U4")
GEMINI_MODEL = "gemini-2.0-flash"  # Use the appropriate model as needed

console = Console()

def format_json_result(result, show_json=True, max_width=100):
    """Format JSON result for display, with optional hiding and width control."""
    if not show_json:
        return "<JSON result hidden>"
    
    if isinstance(result, dict):
        try:
            # Format with indentation and width control
            formatted = json.dumps(result, indent=2)
            
            # If the formatted result is too wide, try to compact it
            if any(len(line) > max_width for line in formatted.split('\n')):
                # Compact version with minimal formatting
                formatted = json.dumps(result, indent=1)
            
            # Create syntax-highlighted JSON
            return Syntax(formatted, "json", theme="monokai", word_wrap=True)
        except Exception:
            return str(result)
    return str(result)

def parse_arguments():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="""MCP-Gemini Agent: A Python client that connects to MCP Bridge Node.Js and uses Google's Gemini LLM to process 
user requests and execute MCP tools commands.

This agent provides natural language interaction with MCP tools through an intelligent LLM-powered 
interface, supporting multi-step reasoning for complex operations, security confirmations, and 
configurable display options.
""",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Basic usage with default settings
  python llm_test.py
  
  # Hide JSON results for cleaner output
  python llm_test.py --hide-json
  
  # Connect to a custom MCP Bridge server
  python llm_test.py --mcp-url http://192.168.1.100:3000
  
  # Connect to a different port
  python llm_test.py --mcp-port 4000
  
  # Adjust JSON width display for better formatting
  python llm_test.py --json-width 120

For more information, visit: https://github.com/INQUIRELAB/mcp-bridge-api
"""
    )
    
    connection_group = parser.add_argument_group('Connection Options', 'Configure the connection to MCP Bridge')
    connection_group.add_argument(
        "--mcp-url",
        type=str,
        default=DEFAULT_MCP_BRIDGE_URL,
        help=f"MCP Bridge URL including protocol and port (default: {DEFAULT_MCP_BRIDGE_URL})"
    )
    connection_group.add_argument(
        "--mcp-port",
        type=int,
        help="Override port in MCP Bridge URL (default: use port from --mcp-url)"
    )
    
    display_group = parser.add_argument_group('Display Options', 'Configure how information is displayed')
    display_group.add_argument(
        "--hide-json",
        action="store_true",
        help="Hide JSON results from tool executions for cleaner output"
    )
    display_group.add_argument(
        "--json-width",
        type=int,
        default=100,
        help="Maximum width for JSON output (default: 100)"
    )
    
    # Add a version argument
    parser.add_argument(
        "--version",
        action="version",
        version="MCP-Gemini Agent v1.0.0",
        help="Show the version information and exit"
    )
    
    return parser.parse_args()

def get_mcp_url(args):
    """Construct the MCP Bridge URL from arguments."""
    mcp_url = args.mcp_url
    
    # If port is specified separately, update the URL
    if args.mcp_port:
        import urllib.parse
        parsed_url = urllib.parse.urlparse(mcp_url)
        # Reconstruct the URL with the new port
        mcp_url = urllib.parse.urlunparse((
            parsed_url.scheme,
            f"{parsed_url.netloc.split(':')[0]}:{args.mcp_port}",
            parsed_url.path,
            parsed_url.params,
            parsed_url.query,
            parsed_url.fragment
        ))
    
    return mcp_url

def setup_gemini():
    """Configure Gemini API with credentials."""
    if not GEMINI_API_KEY:
        raise ValueError("GEMINI_API_KEY environment variable is not set")
    
    genai.configure(api_key=GEMINI_API_KEY)
    model = GenerativeModel(GEMINI_MODEL)
    console.print("[bold green]✓[/bold green] Gemini API configured successfully")
    return model

def get_all_servers(mcp_bridge_url):
    """Get list of all servers from MCP Bridge."""
    try:
        response = requests.get(f"{mcp_bridge_url}/servers")
        response.raise_for_status()
        return response.json().get("servers", [])
    except requests.RequestException as e:
        console.print(f"[bold red]Error getting servers:[/bold red] {e}")
        return []

def get_server_tools(server_id, mcp_bridge_url):
    """Get all tools for a specific server."""
    try:
        response = requests.get(f"{mcp_bridge_url}/servers/{server_id}/tools")
        response.raise_for_status()
        return response.json().get("tools", [])
    except requests.RequestException as e:
        console.print(f"[bold red]Error getting tools for server {server_id}:[/bold red] {e}")
        return []

def get_all_tools(mcp_bridge_url):
    """Get all tools from all servers."""
    servers = get_all_servers(mcp_bridge_url)
    all_tools = {}
    
    for server in servers:
        server_id = server["id"]
        tools = get_server_tools(server_id, mcp_bridge_url)
        all_tools[server_id] = tools
    
    return all_tools

def create_tools_description(all_tools):
    """Create a description of all available tools for the system instruction."""
    tools_description = "Available tools by server:\n\n"
    
    for server_id, tools in all_tools.items():
        tools_description += f"## Server: {server_id}\n\n"
        
        for tool in tools:
            tools_description += f"### {tool['name']}\n"
            tools_description += f"Description: {tool.get('description', 'No description')}\n"
            
            # Add input schema information if available
            if "inputSchema" in tool:
                tools_description += "Parameters:\n"
                if "properties" in tool["inputSchema"]:
                    for param, details in tool["inputSchema"]["properties"].items():
                        param_type = details.get("type", "any")
                        param_desc = details.get("description", "")
                        tools_description += f"- {param} ({param_type}): {param_desc}\n"
                
                # Add required parameters if available
                if "required" in tool["inputSchema"]:
                    tools_description += f"Required parameters: {', '.join(tool['inputSchema']['required'])}\n"
            
            tools_description += "\n"
    
    return tools_description

def create_system_instruction(all_tools):
    """Create a system instruction for Gemini that includes all available tools."""
    tools_description = create_tools_description(all_tools)
    
    system_instruction = f"""
You are an AI assistant that uses available MCP tools to help users accomplish tasks.
When responding, you must ALWAYS return answers in the following JSON format:
{{
  "tool_call": {{
    "server_id": "string or null",
    "tool_name": "string or null",
    "parameters": {{}} or null
  }},
  "response": "string"
}}

If you need to use a tool, fill in the server_id, tool_name, and parameters fields.
If you don't need to use a tool, set server_id, tool_name, and parameters to null.

Your response field should always contain your message to the user.

Here's information about all the tools you can use:

{tools_description}

When a user asks for something that requires using these tools:
1. Figure out which tool is most appropriate
2. Format a proper JSON response with the tool_call filled in
3. Make your response helpful and conversational

When you receive feedback about a tool execution:
1. If you need to make another tool call based on the previous result, include it in your tool_call
2. If no more calls are needed, set server_id, tool_name, and parameters to null
3. Provide a helpful message about the final result in the response field

For file operations:
1. Always check allowed directories first using list_allowed_directories
2. Create files and directories only within allowed directories
3. Provide clear feedback about what you're doing at each step

IMPORTANT: Some tool operations may require user confirmation for security reasons.
If a tool execution returns a result containing "requires_confirmation": true, you should:
1. Inform the user that confirmation is required
2. Explain the risk level and what operation needs confirmation
3. Ask them to explicitly confirm if they want to proceed
"""
    
    return system_instruction.strip()

def execute_tool(server_id, tool_name, parameters, mcp_bridge_url):
    """Execute a tool on an MCP server."""
    try:
        url = f"{mcp_bridge_url}/servers/{server_id}/tools/{tool_name}"
        response = requests.post(url, json=parameters)
        response.raise_for_status()
        return response.json(), None
    except requests.RequestException as e:
        error_message = f"Error executing tool: {e}"
        if response := getattr(e, 'response', None):
            try:
                error_detail = response.json()
                error_message = f"Error: {error_detail.get('error', str(e))}"
            except:
                pass
        return None, error_message

def confirm_operation(confirmation_data, mcp_bridge_url):
    """Process a confirmation request for medium/high risk operations."""
    console.print(Panel(
        f"[bold yellow]⚠️ Security Confirmation Required[/bold yellow]\n\n"
        f"Operation: [bold]{confirmation_data['method']}[/bold] on server [bold]{confirmation_data['server_id']}[/bold]\n"
        f"Tool: [bold]{confirmation_data['tool_name']}[/bold]\n"
        f"Risk Level: [bold]{confirmation_data['risk_level']}[/bold] ({confirmation_data['risk_description']})\n"
        f"Expires: {confirmation_data['expires_at']}\n\n"
        "This operation requires explicit confirmation for security reasons.",
        title="Security Confirmation",
        border_style="yellow"
    ))
    
    # Ask for user confirmation
    confirmed = Confirm.ask("Do you want to proceed with this operation?", default=False)
    
    if confirmed:
        try:
            url = f"{mcp_bridge_url}/confirmations/{confirmation_data['confirmation_id']}"
            response = requests.post(url, json={"confirm": True})
            response.raise_for_status()
            return response.json(), None
        except requests.RequestException as e:
            error_message = f"Error confirming operation: {e}"
            if response := getattr(e, 'response', None):
                try:
                    error_detail = response.json()
                    error_message = f"Error: {error_detail.get('error', str(e))}"
                except:
                    pass
            return None, error_message
    else:
        try:
            url = f"{mcp_bridge_url}/confirmations/{confirmation_data['confirmation_id']}"
            response = requests.post(url, json={"confirm": False})
            response.raise_for_status()
            return {"status": "rejected", "message": "User rejected the operation"}, None
        except requests.RequestException as e:
            return {"status": "rejected", "message": "User rejected the operation"}, None

def process_llm_response(text):
    """Process the LLM response to extract the JSON part."""
    # Try to find JSON in the response
    try:
        # Look for JSON content - sometimes the model might wrap it with ```json
        if "```json" in text:
            json_text = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            json_text = text.split("```")[1].strip()
        else:
            # Otherwise, just try to parse the text directly
            json_text = text.strip()
            
        response_data = json.loads(json_text)
        
        # Ensure the response has the expected structure
        if not isinstance(response_data, dict):
            response_data = {
                "tool_call": None,
                "response": str(response_data)
            }
        elif "tool_call" not in response_data:
            response_data["tool_call"] = None
        elif "response" not in response_data:
            response_data["response"] = ""
            
        return response_data
    except (json.JSONDecodeError, IndexError) as e:
        console.print(f"[bold red]Error parsing LLM response as JSON:[/bold red] {e}")
        console.print(f"Original response: {text}")
        # Return a default structure
        return {
            "tool_call": None,
            "response": "I couldn't format my response properly. Please try again with a clearer request."
        }

def main():
    """Main function to run the MCP-Gemini Agent."""
    # Parse command line arguments
    args = parse_arguments()
    show_json = not args.hide_json
    json_width = args.json_width
    mcp_bridge_url = get_mcp_url(args)
    
    console.print("[bold]MCP-Gemini Agent with Multi-Step Reasoning[/bold]")
    if not show_json:
        console.print("[yellow]JSON result display is disabled[/yellow]")
    console.print(f"Connecting to MCP Bridge at {mcp_bridge_url}...\n")
    
    # Check MCP Bridge connection
    try:
        health_response = requests.get(f"{mcp_bridge_url}/health")
        health_response.raise_for_status()
        console.print(f"[bold green]✓[/bold green] Connected to MCP Bridge: {health_response.json()['serverCount']} servers found")
    except requests.RequestException as e:
        console.print(f"[bold red]Error connecting to MCP Bridge at {mcp_bridge_url}:[/bold red] {e}")
        console.print("Please make sure MCP Bridge is running. Exiting...")
        return
    
    # Setup Gemini
    try:
        model = setup_gemini()
    except Exception as e:
        console.print(f"[bold red]Error setting up Gemini:[/bold red] {e}")
        return
    
    # Get all tools from all servers
    all_tools = get_all_tools(mcp_bridge_url)
    if not all_tools:
        console.print("[bold yellow]Warning:[/bold yellow] No tools found from any server.")
    else:
        console.print(f"[bold green]✓[/bold green] Found tools from {len(all_tools)} servers")
    
    # Create system instruction with tools information
    system_instruction = create_system_instruction(all_tools)
    
    # Create chat session
    console.print("\n[bold]Starting chat session. Type 'exit' to quit.[/bold]\n")
    
    # Initialize chat
    chat = model.start_chat(history=[])
    chat.send_message(system_instruction)  # Send system instruction as first message
    
    # Main chat loop
    while True:
        # Get user input
        user_input = input("You: ")
        if user_input.lower() in ["exit", "quit"]:
            break
        
        # Send message to Gemini
        response = chat.send_message(user_input)
        
        # Process the response
        processed_response = process_llm_response(response.text)
        
        # Display the text response part
        console.print("\nAI:", style="bold")
        console.print(Markdown(processed_response["response"]))
        
        # Extract tool call information
        tool_call = processed_response.get("tool_call") or {}
        
        # Continue as long as there's a tool call to make
        while tool_call and all(tool_call.get(k) is not None for k in ["server_id", "tool_name", "parameters"]):
            server_id = tool_call.get("server_id")
            tool_name = tool_call.get("tool_name")
            parameters = tool_call.get("parameters")
            
            # Show the tool call parameters
            if show_json:
                console.print(f"\n[bold yellow]Executing tool:[/bold yellow] {server_id}/{tool_name}")
                console.print("Parameters:", style="bold")
                console.print(format_json_result(parameters, show_json=True, max_width=json_width))
            else:
                console.print(f"\n[bold yellow]Executing tool:[/bold yellow] {server_id}/{tool_name} (parameters hidden)")
            
            # Execute the tool
            result, error = execute_tool(server_id, tool_name, parameters, mcp_bridge_url)
            
            # Check if the operation requires confirmation
            if error is None and isinstance(result, dict) and result.get("requires_confirmation") is True:
                console.print("[bold yellow]Operation requires security confirmation[/bold yellow]")
                # Handle the confirmation
                result, error = confirm_operation(result, mcp_bridge_url)
            
            # Handle errors
            if error:
                console.print(f"[bold red]Tool execution failed:[/bold red] {error}")
                tool_feedback = f"The tool execution failed with error: {error}"
            else:
                console.print(f"[bold green]Tool execution successful[/bold green]")
                
                # Format and display the result
                if isinstance(result, dict):
                    result_str = json.dumps(result, indent=2)
                else:
                    result_str = str(result)
                
                # Display the result based on show_json setting
                console.print("Result:", style="bold")
                console.print(format_json_result(result, show_json, json_width))
                
                # Check if the operation was rejected by the user
                if isinstance(result, dict) and result.get("status") == "rejected":
                    tool_feedback = f"The operation was cancelled by the user: {result.get('message', 'No reason provided')}"
                else:
                    tool_feedback = f"The tool {tool_name} was executed successfully. Result: {result_str}"
            
            # Send feedback to Gemini
            response = chat.send_message(tool_feedback)
            processed_response = process_llm_response(response.text)
            
            # Display the feedback response
            console.print("\nAI:", style="bold")
            console.print(Markdown(processed_response["response"]))
            
            # Get the next tool call if any
            tool_call = processed_response.get("tool_call") or {}
        
        console.print("\n" + "-" * 50 + "\n")

if __name__ == "__main__":
    main()

================
File: mcp-bridge.js
================
#!/usr/bin/env node

/**
 * MCP Bridge - RESTful Proxy for Model Context Protocol Servers
 * A lightweight, LLM-agnostic proxy that connects to multiple MCP servers
 * and exposes their capabilities through a unified REST API.
 */

// Import dependencies
const express = require('express');
const cors = require('cors');
const { spawn } = require('child_process');
const fs = require('fs');
const path = require('path');
const morgan = require('morgan');
const { v4: uuidv4 } = require('uuid');

// Risk level constants
const RISK_LEVEL = {
  LOW: 1,
  MEDIUM: 2,
  HIGH: 3
};

// Risk level descriptions
const RISK_LEVEL_DESCRIPTION = {
  [RISK_LEVEL.LOW]: "Low risk - Standard execution",
  [RISK_LEVEL.MEDIUM]: "Medium risk - Requires confirmation",
  [RISK_LEVEL.HIGH]: "High risk - Docker execution required"
};

console.log('Starting MCP Bridge...');

// Create Express application
const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors());
app.use(express.json());
app.use(morgan('dev'));

console.log('Middleware configured');

// Server state
const serverProcesses = new Map(); // Map of server IDs to processes
const pendingConfirmations = new Map(); // Map of request IDs to pending confirmations

// Helper function to load server configuration from file or environment
function loadServerConfig() {
  console.log('Loading server configuration...');
  let config = {};
  
  // Try to load from config file
  const configPath = process.env.MCP_CONFIG_PATH || path.join(process.cwd(), 'mcp_config.json');
  console.log(`Checking for config file at: ${configPath}`);
  
  try {
    if (fs.existsSync(configPath)) {
      const configFile = fs.readFileSync(configPath, 'utf8');
      config = JSON.parse(configFile).mcpServers || {};
      console.log(`Loaded configuration from ${configPath}:`, Object.keys(config));
      
      // For backward compatibility, validate risk levels if present
      for (const [serverId, serverConfig] of Object.entries(config)) {
        if (serverConfig.riskLevel !== undefined) {
          if (![RISK_LEVEL.LOW, RISK_LEVEL.MEDIUM, RISK_LEVEL.HIGH].includes(serverConfig.riskLevel)) {
            console.warn(`Warning: Invalid risk level ${serverConfig.riskLevel} for server ${serverId}, ignoring risk level`);
            delete serverConfig.riskLevel;
          } else if (serverConfig.riskLevel === RISK_LEVEL.HIGH && (!serverConfig.docker || !serverConfig.docker.image)) {
            console.warn(`Warning: Server ${serverId} has HIGH risk level but no docker configuration, downgrading to MEDIUM risk level`);
            serverConfig.riskLevel = RISK_LEVEL.MEDIUM;
          }
        }
      }
    } else {
      console.log(`No configuration file found at ${configPath}, using defaults or environment variables`);
    }
  } catch (error) {
    console.error(`Error loading configuration file: ${error.message}`);
  }
  
  // Allow environment variables to override config
  // Format: MCP_SERVER_NAME_COMMAND, MCP_SERVER_NAME_ARGS (comma-separated)
  Object.keys(process.env).forEach(key => {
    if (key.startsWith('MCP_SERVER_') && key.endsWith('_COMMAND')) {
      const serverName = key.replace('MCP_SERVER_', '').replace('_COMMAND', '').toLowerCase();
      const command = process.env[key];
      const argsKey = `MCP_SERVER_${serverName.toUpperCase()}_ARGS`;
      const args = process.env[argsKey] ? process.env[argsKey].split(',') : [];
      
      // Create or update server config
      config[serverName] = {
        command,
        args
      };
      
      // Check for environment variables
      const envKey = `MCP_SERVER_${serverName.toUpperCase()}_ENV`;
      if (process.env[envKey]) {
        try {
          config[serverName].env = JSON.parse(process.env[envKey]);
        } catch (error) {
          console.error(`Error parsing environment variables for ${serverName}: ${error.message}`);
        }
      }
      
      // Check for risk level
      const riskLevelKey = `MCP_SERVER_${serverName.toUpperCase()}_RISK_LEVEL`;
      if (process.env[riskLevelKey]) {
        try {
          const riskLevel = parseInt(process.env[riskLevelKey], 10);
          if ([RISK_LEVEL.LOW, RISK_LEVEL.MEDIUM, RISK_LEVEL.HIGH].includes(riskLevel)) {
            config[serverName].riskLevel = riskLevel;
            
            // For high risk level, check for docker configuration
            if (riskLevel === RISK_LEVEL.HIGH) {
              const dockerConfigKey = `MCP_SERVER_${serverName.toUpperCase()}_DOCKER_CONFIG`;
              if (process.env[dockerConfigKey]) {
                try {
                  config[serverName].docker = JSON.parse(process.env[dockerConfigKey]);
                } catch (error) {
                  console.error(`Error parsing docker configuration for ${serverName}: ${error.message}`);
                  console.warn(`Server ${serverName} has HIGH risk level but invalid docker configuration, downgrading to MEDIUM risk level`);
                  config[serverName].riskLevel = RISK_LEVEL.MEDIUM;
                }
              } else {
                console.warn(`Server ${serverName} has HIGH risk level but no docker configuration, downgrading to MEDIUM risk level`);
                config[serverName].riskLevel = RISK_LEVEL.MEDIUM;
              }
            }
          } else {
            console.warn(`Invalid risk level ${riskLevel} for server ${serverName}, ignoring risk level`);
          }
        } catch (error) {
          console.error(`Error parsing risk level for ${serverName}: ${error.message}`);
        }
      }
      
      console.log(`Added server from environment: ${serverName}`);
    }
  });
  
  console.log(`Loaded ${Object.keys(config).length} server configurations`);
  return config;
}

// Initialize and connect to MCP servers
async function initServers() {
  console.log('Initializing MCP servers...');
  const serverConfig = loadServerConfig();
  
  console.log('Server configurations found:');
  console.log(JSON.stringify(serverConfig, null, 2));
  
  // Start each configured server
  for (const [serverId, config] of Object.entries(serverConfig)) {
    try {
      console.log(`Starting server: ${serverId}`);
      await startServer(serverId, config);
      console.log(`Server ${serverId} initialized successfully`);
    } catch (error) {
      console.error(`Failed to initialize server ${serverId}: ${error.message}`);
    }
  }
  
  console.log('All servers initialized');
}

// Start a specific MCP server
async function startServer(serverId, config) {
  console.log(`Starting MCP server process: ${serverId} with command: ${config.command} ${config.args.join(' ')}`);
  
  // Set default risk level to undefined for backward compatibility
  const riskLevel = config.riskLevel;
  
  if (riskLevel !== undefined) {
    console.log(`Server ${serverId} has risk level: ${riskLevel} (${RISK_LEVEL_DESCRIPTION[riskLevel]})`);
    
    // For high risk level, verify docker is configured
    if (riskLevel === RISK_LEVEL.HIGH) {
      if (!config.docker || typeof config.docker !== 'object') {
        throw new Error(`Server ${serverId} has HIGH risk level but no docker configuration`);
      }
      
      console.log(`Server ${serverId} will be started in docker container`);
    }
  } else {
    console.log(`Server ${serverId} has no risk level specified - using standard execution`);
  }
  
  return new Promise((resolve, reject) => {
    try {
      // Get the npm path
      let commandPath = config.command;
      
      // If high risk, use docker
      if (riskLevel !== undefined && riskLevel === RISK_LEVEL.HIGH) {
        commandPath = 'docker';
        const dockerArgs = ['run', '--rm'];
        
        // Add any environment variables
        if (config.env && typeof config.env === 'object') {
          Object.entries(config.env).forEach(([key, value]) => {
            dockerArgs.push('-e', `${key}=${value}`);
          });
        }
        
        // Add volume mounts if specified
        if (config.docker.volumes && Array.isArray(config.docker.volumes)) {
          config.docker.volumes.forEach(volume => {
            dockerArgs.push('-v', volume);
          });
        }
        
        // Add network configuration if specified
        if (config.docker.network) {
          dockerArgs.push('--network', config.docker.network);
        }
        
        // Add the image and command
        dockerArgs.push(config.docker.image);
        
        // If original command was a specific executable, use it as the command in the container
        if (config.command !== 'npm' && config.command !== 'npx') {
          dockerArgs.push(config.command);
        }
        
        // Add the original args
        dockerArgs.push(...config.args);
        
        // Update args to use docker
        config = {
          ...config,
          originalCommand: config.command,
          command: commandPath,
          args: dockerArgs,
          riskLevel // Keep the risk level
        };
        
        console.log(`Transformed command for docker: ${commandPath} ${dockerArgs.join(' ')}`);
      }
      // If the command is npx or npm, try to find their full paths
      else if (config.command === 'npx' || config.command === 'npm') {
        // On Windows, try to use the npm executable from standard locations
        if (process.platform === 'win32') {
          const possiblePaths = [
            // Global npm installation
            path.join(process.env.APPDATA || '', 'npm', `${config.command}.cmd`),
            // Node installation directory
            path.join(process.env.ProgramFiles || '', 'nodejs', `${config.command}.cmd`),
            // Common Node installation location
            path.join('C:\\Program Files\\nodejs', `${config.command}.cmd`),
          ];
          
          for (const possiblePath of possiblePaths) {
            if (fs.existsSync(possiblePath)) {
              console.log(`Found ${config.command} at ${possiblePath}`);
              commandPath = possiblePath;
              break;
            }
          }
        } else {
          // On Unix-like systems, try using which to find the command
          try {
            const { execSync } = require('child_process');
            const whichOutput = execSync(`which ${config.command}`).toString().trim();
            if (whichOutput) {
              console.log(`Found ${config.command} at ${whichOutput}`);
              commandPath = whichOutput;
            }
          } catch (error) {
            console.error(`Error finding full path for ${config.command}:`, error.message);
          }
        }
      }
      
      console.log(`Using command path: ${commandPath}`);
      
      // Special handling for Windows command prompt executables (.cmd files)
      const isWindowsCmd = process.platform === 'win32' && commandPath.endsWith('.cmd');
      const actualCommand = isWindowsCmd ? 'cmd' : commandPath;
      const actualArgs = isWindowsCmd ? ['/c', commandPath, ...config.args] : config.args;
      
      console.log(`Spawning process with command: ${actualCommand} and args:`, actualArgs);
      
      // Combine environment variables
      const envVars = { ...process.env };
      
      // Add custom environment variables if provided
      if (config.env && typeof config.env === 'object') {
        console.log(`Adding environment variables for ${serverId}:`, config.env);
        Object.assign(envVars, config.env);
      } else {
        console.log(`No custom environment variables for ${serverId}`);
      }
      
      // Spawn the server process with shell option for better compatibility
      const serverProcess = spawn(actualCommand, actualArgs, {
        env: envVars,
        stdio: 'pipe',
        shell: !isWindowsCmd // Use shell only if not handling Windows .cmd specially
      });
      
      console.log(`Server process spawned for ${serverId}, PID: ${serverProcess.pid}`);
      
      // Store the server process with its risk level
      serverProcesses.set(serverId, {
        process: serverProcess,
        riskLevel,
        pid: serverProcess.pid,
        config
      });
      
      // Set up communication
      const setupMCPCommunication = () => {
        // Send initialize request to the MCP server
        const initializeRequest = {
          jsonrpc: "2.0",
          id: 1,
          method: "initialize",
          params: {
            protocolVersion: "0.3.0",
            clientInfo: {
              name: "mcp-bridge",
              version: "1.0.0"
            },
            capabilities: {
              // Add capabilities as needed
            }
          }
        };
        
        serverProcess.stdin.write(JSON.stringify(initializeRequest) + '\n');
        console.log(`Sent initialize request to ${serverId}`);
      };
      
      // Set up various event listeners
      serverProcess.stdout.on('data', (data) => {
        console.log(`[${serverId}] STDOUT: ${data.toString().trim()}`);
      });
      
      serverProcess.stderr.on('data', (data) => {
        console.log(`[${serverId}] STDERR: ${data.toString().trim()}`);
      });
      
      serverProcess.on('error', (error) => {
        console.error(`[${serverId}] Process error: ${error.message}`);
        reject(error);
      });
      
      serverProcess.on('close', (code) => {
        console.log(`[${serverId}] Process exited with code ${code}`);
        serverProcesses.delete(serverId);
      });
      
      // Wait a moment for the process to start
      setTimeout(() => {
        setupMCPCommunication();
        resolve(serverProcess);
      }, 1000);
    } catch (error) {
      console.error(`Error starting server ${serverId}:`, error);
      reject(error);
    }
  });
}

// Shutdown an MCP server
async function shutdownServer(serverId) {
  console.log(`Shutting down server: ${serverId}`);
  const serverInfo = serverProcesses.get(serverId);
  
  if (serverInfo) {
    try {
      console.log(`Killing process for ${serverId}`);
      serverInfo.process.kill();
    } catch (error) {
      console.error(`Error killing process for ${serverId}: ${error.message}`);
    }
    
    serverProcesses.delete(serverId);
  }
  
  console.log(`Server ${serverId} shutdown complete`);
}

// MCP request handler
async function sendMCPRequest(serverId, method, params = {}, confirmationId = null) {
  return new Promise((resolve, reject) => {
    const serverInfo = serverProcesses.get(serverId);
    
    if (!serverInfo) {
      return reject(new Error(`Server '${serverId}' not found or not connected`));
    }
    
    const { process: serverProcess, riskLevel, config } = serverInfo;
    
    // Only perform risk level checks if explicitly configured (for backward compatibility)
    if (riskLevel !== undefined && riskLevel === RISK_LEVEL.MEDIUM && method === 'tools/call' && !confirmationId) {
      // Generate a confirmation ID for this request
      const pendingId = uuidv4();
      console.log(`Medium risk level request for ${serverId}/${method} - requires confirmation (ID: ${pendingId})`);
      
      // Store the pending confirmation
      pendingConfirmations.set(pendingId, {
        serverId,
        method,
        params,
        timestamp: Date.now()
      });
      
      // Return a response that requires confirmation
      return resolve({
        requires_confirmation: true,
        confirmation_id: pendingId,
        risk_level: riskLevel,
        risk_description: RISK_LEVEL_DESCRIPTION[riskLevel],
        server_id: serverId,
        method,
        tool_name: params.name,
        expires_at: new Date(Date.now() + 10 * 60 * 1000).toISOString() // 10 minutes
      });
    }
    
    const requestId = uuidv4();
    
    const request = {
      jsonrpc: "2.0",
      id: requestId,
      method,
      params
    };
    
    console.log(`Sending request to ${serverId}: ${method}`, params);
    
    // Set up one-time response handler
    const messageHandler = (data) => {
      try {
        const responseText = data.toString();
        const lines = responseText.split('\n').filter(line => line.trim());
        
        for (const line of lines) {
          try {
            const response = JSON.parse(line);
            
            if (response.id === requestId) {
              console.log(`Received response from ${serverId} for request ${requestId}`);
              
              // Remove handler after response is received
              serverProcess.stdout.removeListener('data', messageHandler);
              
              if (response.error) {
                return reject(new Error(response.error.message || 'Unknown error'));
              }
              
              // For high risk level, add information about docker execution (only if risk level is explicitly set)
              if (riskLevel !== undefined && riskLevel === RISK_LEVEL.HIGH) {
                const result = response.result || {};
                return resolve({
                  ...result,
                  execution_environment: {
                    risk_level: riskLevel,
                    risk_description: RISK_LEVEL_DESCRIPTION[riskLevel],
                    docker: true,
                    docker_image: config.docker?.image || 'unknown'
                  }
                });
              }
              
              return resolve(response.result);
            }
          } catch (parseError) {
            console.error(`Error parsing JSON response from ${serverId}:`, parseError);
          }
        }
      } catch (error) {
        console.error(`Error processing response from ${serverId}:`, error);
      }
    };
    
    // Add temporary response handler
    serverProcess.stdout.on('data', messageHandler);
    
    // Set a timeout for the request
    const timeout = setTimeout(() => {
      serverProcess.stdout.removeListener('data', messageHandler);
      reject(new Error(`Request to ${serverId} timed out after 10 seconds`));
    }, 10000);
    
    // Send the request
    serverProcess.stdin.write(JSON.stringify(request) + '\n');
    
    // Handle error case
    serverProcess.on('error', (error) => {
      clearTimeout(timeout);
      serverProcess.stdout.removeListener('data', messageHandler);
      reject(error);
    });
  });
}

// API Routes
console.log('Setting up API routes');

// Get server status
app.get('/servers', (req, res) => {
  console.log('GET /servers');
  const servers = Array.from(serverProcesses.entries()).map(([id, info]) => {
    // Create base server info
    const serverInfo = {
      id,
      connected: true,
      pid: info.pid
    };
    
    // Only include risk level information if it was explicitly set
    if (info.riskLevel !== undefined) {
      serverInfo.risk_level = info.riskLevel;
      serverInfo.risk_description = RISK_LEVEL_DESCRIPTION[info.riskLevel];
      
      if (info.riskLevel === RISK_LEVEL.HIGH) {
        serverInfo.running_in_docker = true;
      }
    }
    
    return serverInfo;
  });
  
  console.log(`Returning ${servers.length} servers`);
  res.json({ servers });
});

// Start a new server (manual configuration)
app.post('/servers', async (req, res) => {
  console.log('POST /servers', req.body);
  try {
    const { id, command, args, env, riskLevel, docker } = req.body;
    
    if (!id || !command) {
      console.log('Missing required fields');
      return res.status(400).json({
        error: "Server ID and command are required"
      });
    }
    
    if (serverProcesses.has(id)) {
      console.log(`Server with ID '${id}' already exists`);
      return res.status(409).json({
        error: `Server with ID '${id}' already exists`
      });
    }
    
    // Validate risk level if provided
    if (riskLevel !== undefined) {
      if (![RISK_LEVEL.LOW, RISK_LEVEL.MEDIUM, RISK_LEVEL.HIGH].includes(riskLevel)) {
        return res.status(400).json({
          error: `Invalid risk level: ${riskLevel}. Valid values are: ${RISK_LEVEL.LOW} (low), ${RISK_LEVEL.MEDIUM} (medium), ${RISK_LEVEL.HIGH} (high)`
        });
      }
      
      // For high risk level, docker config is required
      if (riskLevel === RISK_LEVEL.HIGH && (!docker || !docker.image)) {
        return res.status(400).json({
          error: "Docker configuration with 'image' property is required for high risk level servers"
        });
      }
    }
    
    // Create the configuration object - only include riskLevel if explicitly set
    const config = { 
      command, 
      args: args || [], 
      env: env || {}
    };
    
    // Only add risk level if explicitly provided
    if (riskLevel !== undefined) {
      config.riskLevel = riskLevel;
      
      // Add docker config if provided for high risk levels
      if (riskLevel === RISK_LEVEL.HIGH && docker) {
        config.docker = docker;
      }
    }
    
    console.log(`Starting server '${id}' with config:`, config);
    await startServer(id, config);
    
    const serverInfo = serverProcesses.get(id);
    console.log(`Server '${id}' started successfully`);
    
    // Create response object
    const response = {
      id,
      status: "connected",
      pid: serverInfo.pid
    };
    
    // Only include risk level information if explicitly set
    if (serverInfo.riskLevel !== undefined) {
      response.risk_level = serverInfo.riskLevel;
      response.risk_description = RISK_LEVEL_DESCRIPTION[serverInfo.riskLevel];
      
      if (serverInfo.riskLevel === RISK_LEVEL.HIGH) {
        response.running_in_docker = true;
      }
    }
    
    res.status(201).json(response);
  } catch (error) {
    console.error(`Error starting server: ${error.message}`);
    res.status(500).json({
      error: error.message
    });
  }
});

// Stop a server
app.delete('/servers/:serverId', async (req, res) => {
  const { serverId } = req.params;
  console.log(`DELETE /servers/${serverId}`);
  
  if (!serverProcesses.has(serverId)) {
    console.log(`Server '${serverId}' not found`);
    return res.status(404).json({
      error: `Server '${serverId}' not found`
    });
  }
  
  try {
    console.log(`Shutting down server '${serverId}'`);
    await shutdownServer(serverId);
    console.log(`Server '${serverId}' shutdown complete`);
    res.json({
      status: "disconnected"
    });
  } catch (error) {
    console.error(`Error stopping server ${serverId}: ${error.message}`);
    res.status(500).json({
      error: error.message
    });
  }
});

// Get tools for a server
app.get('/servers/:serverId/tools', async (req, res) => {
  const { serverId } = req.params;
  console.log(`GET /servers/${serverId}/tools`);
  
  try {
    if (!serverProcesses.has(serverId)) {
      return res.status(404).json({
        error: `Server '${serverId}' not found or not connected`
      });
    }
    
    const result = await sendMCPRequest(serverId, 'tools/list');
    res.json(result);
  } catch (error) {
    console.error(`Error listing tools for ${serverId}:`, error);
    res.status(500).json({ error: error.message });
  }
});

// Execute a tool on a server
app.post('/servers/:serverId/tools/:toolName', async (req, res) => {
  const { serverId, toolName } = req.params;
  const arguments = req.body;
  
  console.log(`POST /servers/${serverId}/tools/${toolName}`, arguments);
  
  try {
    if (!serverProcesses.has(serverId)) {
      return res.status(404).json({
        error: `Server '${serverId}' not found or not connected`
      });
    }
    
    const serverInfo = serverProcesses.get(serverId);
    
    // Get risk level information for the response
    const riskLevel = serverInfo.riskLevel;
    
    const result = await sendMCPRequest(serverId, 'tools/call', {
      name: toolName,
      arguments
    });
    
    res.json(result);
  } catch (error) {
    console.error(`Error executing tool ${toolName}:`, error);
    res.status(500).json({ error: error.message });
  }
});

// Confirm a medium risk level request
app.post('/confirmations/:confirmationId', async (req, res) => {
  const { confirmationId } = req.params;
  const { confirm } = req.body;
  
  console.log(`POST /confirmations/${confirmationId}`, req.body);
  
  // Check if the confirmation exists
  if (!pendingConfirmations.has(confirmationId)) {
    return res.status(404).json({
      error: `Confirmation '${confirmationId}' not found or expired`
    });
  }
  
  const pendingRequest = pendingConfirmations.get(confirmationId);
  
  // Check if the confirmation is expired (10 minutes)
  const now = Date.now();
  if (now - pendingRequest.timestamp > 10 * 60 * 1000) {
    pendingConfirmations.delete(confirmationId);
    return res.status(410).json({
      error: `Confirmation '${confirmationId}' has expired`
    });
  }
  
  // If not confirmed, just delete the pending request
  if (!confirm) {
    pendingConfirmations.delete(confirmationId);
    return res.json({
      status: "rejected",
      message: "Request was rejected by the user"
    });
  }
  
  try {
    // Execute the confirmed request
    console.log(`Executing confirmed request for ${pendingRequest.serverId}`);
    const result = await sendMCPRequest(
      pendingRequest.serverId, 
      pendingRequest.method, 
      pendingRequest.params,
      confirmationId // Pass the confirmation ID to bypass confirmation check
    );
    
    // Delete the pending request
    pendingConfirmations.delete(confirmationId);
    
    // Return the result
    res.json(result);
  } catch (error) {
    console.error(`Error executing confirmed request: ${error.message}`);
    res.status(500).json({ error: error.message });
  }
});

// Get resources for a server
app.get('/servers/:serverId/resources', async (req, res) => {
  const { serverId } = req.params;
  console.log(`GET /servers/${serverId}/resources`);
  
  try {
    if (!serverProcesses.has(serverId)) {
      return res.status(404).json({
        error: `Server '${serverId}' not found or not connected`
      });
    }
    
    const result = await sendMCPRequest(serverId, 'resources/list');
    res.json(result);
  } catch (error) {
    console.error(`Error listing resources for ${serverId}:`, error);
    res.status(500).json({ error: error.message });
  }
});

// Get a specific resource
app.get('/servers/:serverId/resources/:resourceUri', async (req, res) => {
  const { serverId, resourceUri } = req.params;
  console.log(`GET /servers/${serverId}/resources/${resourceUri}`);
  
  try {
    if (!serverProcesses.has(serverId)) {
      return res.status(404).json({
        error: `Server '${serverId}' not found or not connected`
      });
    }
    
    const decodedUri = decodeURIComponent(resourceUri);
    const result = await sendMCPRequest(serverId, 'resources/read', {
      uri: decodedUri
    });
    
    res.json(result);
  } catch (error) {
    console.error(`Error reading resource ${resourceUri}:`, error);
    res.status(500).json({ error: error.message });
  }
});

// Get prompts for a server
app.get('/servers/:serverId/prompts', async (req, res) => {
  const { serverId } = req.params;
  console.log(`GET /servers/${serverId}/prompts`);
  
  try {
    if (!serverProcesses.has(serverId)) {
      return res.status(404).json({
        error: `Server '${serverId}' not found or not connected`
      });
    }
    
    const result = await sendMCPRequest(serverId, 'prompts/list');
    res.json(result);
  } catch (error) {
    console.error(`Error listing prompts for ${serverId}:`, error);
    res.status(500).json({ error: error.message });
  }
});

// Execute a prompt
app.post('/servers/:serverId/prompts/:promptName', async (req, res) => {
  const { serverId, promptName } = req.params;
  const arguments = req.body;
  
  console.log(`POST /servers/${serverId}/prompts/${promptName}`, arguments);
  
  try {
    if (!serverProcesses.has(serverId)) {
      return res.status(404).json({
        error: `Server '${serverId}' not found or not connected`
      });
    }
    
    const result = await sendMCPRequest(serverId, 'prompts/get', {
      name: promptName,
      arguments
    });
    
    res.json(result);
  } catch (error) {
    console.error(`Error executing prompt ${promptName}:`, error);
    res.status(500).json({ error: error.message });
  }
});

// Health check endpoint
app.get('/health', (req, res) => {
  console.log('GET /health');
  
  const servers = Array.from(serverProcesses.entries()).map(([id, info]) => {
    // Create base server info
    const serverInfo = {
      id,
      pid: info.pid
    };
    
    // Only include risk level information if explicitly set
    if (info.riskLevel !== undefined) {
      serverInfo.risk_level = info.riskLevel;
      serverInfo.risk_description = RISK_LEVEL_DESCRIPTION[info.riskLevel];
      
      if (info.riskLevel === RISK_LEVEL.HIGH) {
        serverInfo.running_in_docker = true;
      }
    }
    
    return serverInfo;
  });
  
  res.json({
    status: 'ok',
    uptime: process.uptime(),
    serverCount: serverProcesses.size,
    servers
  });
});

// Start the server
app.listen(PORT, async () => {
  console.log(`MCP Bridge server running on port ${PORT}`);
  await initServers();
  console.log('Ready to handle requests');
});

// Handle graceful shutdown
process.on('SIGTERM', async () => {
  console.log('SIGTERM received, shutting down servers...');
  
  const shutdownPromises = [];
  for (const serverId of serverProcesses.keys()) {
    shutdownPromises.push(shutdownServer(serverId));
  }
  
  await Promise.all(shutdownPromises);
  process.exit(0);
});

process.on('SIGINT', async () => {
  console.log('SIGINT received, shutting down servers...');
  
  const shutdownPromises = [];
  for (const serverId of serverProcesses.keys()) {
    shutdownPromises.push(shutdownServer(serverId));
  }
  
  await Promise.all(shutdownPromises);
  process.exit(0);
});

================
File: README.md
================
# MCP Bridge API

## A Lightweight, LLM-Agnostic RESTful Proxy for Model Context Protocol Servers

**Authors:**  
Arash Ahmadi, Sarah S. Sharif, and Yaser M. Banad*  
School of Electrical, and Computer Engineering, University of Oklahoma, Oklahoma, United States  
*Corresponding author: bana@ou.edu

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

## 📚 Introduction

MCP Bridge is a lightweight, fast, and LLM-agnostic proxy that connects to multiple Model Context Protocol (MCP) servers and exposes their capabilities through a unified REST API. It enables any client on any platform to leverage MCP functionality without process execution constraints. Unlike Anthropic's official MCP SDK, MCP Bridge is fully independent and designed to work with any LLM backend which makes it adaptable, modular, and future-proof for diverse deployments. With optional risk-based execution levels, it provides granular security controls—from standard execution to confirmation workflows and Docker isolation—while maintaining backward compatibility with standard MCP clients. Complementing this server-side infrastructure is the MCP-Gemini Agent, a Python client that integrates Google's Gemini API with MCP Bridge. This agent enables natural language interaction with MCP tools through an intelligent LLM-powered interface that features multi-step reasoning for complex operations, security confirmation workflow handling, and configurable display options for enhanced usability. Together, MCP Bridge's versatile server-side capabilities and the Gemini Agent's intelligent client interface create a powerful ecosystem for developing sophisticated LLM-powered applications.

### ⚠️ The Problem

- Many MCP servers use STDIO transports requiring local process execution
- Edge devices, mobile devices, web browsers, and other platforms cannot efficiently run npm or Python MCP servers
- Direct MCP server connections are impractical in resource-constrained environments
- Multiple isolated clients connecting to the same servers causes redundancy and increases resource usage
- Interacting directly with MCP tools requires technical knowledge of specific tool formats and requirements

## 🏗️ Architecture

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│     Mobile      │     │     Browser     │     │  Other Clients  │
│    Application  │     │   Application   │     │                 │
└────────┬────────┘     └────────┬────────┘     └────────┬────────┘
         │                       │                       │
         │                       │                       │
         │                       ▼                       │
         │           ┌───────────────────────┐          │
         └──────────►│                       │◄─────────┘
                     │      REST API         │
                     │                       │
                     └───────────┬───────────┘
                                 │
                                 ▼
                     ┌───────────────────────┐
                     │                       │
                     │     MCP Bridge        │
                     │                       │
                     └───────────┬───────────┘
                                 │
                 ┌───────────────┼───────────────┐
                 │               │               │
                 ▼               ▼               ▼
        ┌─────────────┐  ┌─────────────┐  ┌─────────────┐
        │  MCP Server │  │  MCP Server │  │  MCP Server │
        │    (STDIO)  │  │    (STDIO)  │  │    (SSE)    │
        └─────────────┘  └─────────────┘  └─────────────┘
```

## 💾 Installation

### 📦 Prerequisites

- Node.js 18+ for MCP Bridge
- Python 3.8+ for the MCP-Gemini Agent

### 🚀 Quick Setup

#### MCP Bridge

```bash
# Install dependencies
npm install express cors morgan uuid

# Start the server
node mcp-bridge.js
```

#### MCP-Gemini Agent

```bash
# Install dependencies
pip install google-generativeai requests rich

# Start the agent
python llm_test.py
```

## ⚙️ Configuration

### MCP Bridge Configuration

MCP Bridge is configured through a JSON file named `mcp_config.json` in the project root. This is an example of a basic MCP config:

```json
{
  "mcpServers": {
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/path/to/directory"],
      "riskLevel": 2
    },
    "slack": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-slack"],
      "env": {
        "SLACK_BOT_TOKEN": "your-slack-token",
        "SLACK_TEAM_ID": "your-team-id"
      },
      "riskLevel": 1
    }
  }
}
```

### MCP-Gemini Agent Configuration

The MCP-Gemini Agent supports several command-line options:

```
usage: llm_test.py [-h] [--hide-json] [--json-width JSON_WIDTH] [--mcp-url MCP_URL] [--mcp-port MCP_PORT]

MCP-Gemini Agent with configurable settings

options:
  -h, --help            show this help message and exit
  --hide-json           Hide JSON results from tool executions
  --json-width JSON_WIDTH
                        Maximum width for JSON output (default: 100)
  --mcp-url MCP_URL     MCP Bridge URL including protocol and port (default: http://localhost:3000)
  --mcp-port MCP_PORT   Override port in MCP Bridge URL (default: use port from --mcp-url)
```

## 🧪 API Usage

MCP Bridge exposes a clean and intuitive REST API for interacting with connected servers. Here's a breakdown of available endpoints:

### 📋 General Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/servers` | GET | List all connected MCP servers |
| `/servers` | POST | Start a new MCP server |
| `/servers/{serverId}` | DELETE | Stop and remove an MCP server |
| `/health` | GET | Get health status of the MCP Bridge |
| `/confirmations/{confirmationId}` | POST | Confirm execution of a medium risk level request |

### 📌 Server-Specific Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/servers/{serverId}/tools` | GET | List all tools for a specific server |
| `/servers/{serverId}/tools/{toolName}` | POST | Execute a specific tool |
| `/servers/{serverId}/resources` | GET | List all resources |
| `/servers/{serverId}/resources/{resourceUri}` | GET | Retrieve specific resource content |
| `/servers/{serverId}/prompts` | GET | List all prompts |
| `/servers/{serverId}/prompts/{promptName}` | POST | Execute a prompt with arguments |

## 🧪 Example Requests

### 📂 Read Directory (Filesystem)

```http
POST /servers/filesystem/tools/list_directory
Content-Type: application/json

{
  "path": "."
}
```

## 🧪 MCP-Gemini Agent Features

The MCP-Gemini Agent is a Python-based client that connects to MCP Bridge Node.JS server and uses Google's Gemini LLM to process user requests and execute MCP tools commands. Key features:

1. **Multi-step reasoning** - Supports sequenced tool calls for complex operations
2. **Security confirmation flow** - Integrated handling for medium and high risk operations
3. **Flexible JSON display** - Control the verbosity of JSON outputs for better readability
4. **Configurable connection** - Connect to any MCP Bridge instance with custom URL and port
5. **Discovery of available tools** - Automatically detects and uses all tools from connected servers

Example usage:

```bash
# Basic usage with default settings
python llm_test.py

# Hide JSON results for cleaner output
python llm_test.py --hide-json

# Connect to a custom MCP Bridge server
python llm_test.py --mcp-url http://192.168.1.100:3000

# Connect to a different port
python llm_test.py --mcp-port 4000

# Adjust JSON width display for better formatting
python llm_test.py --json-width 120
```

## 🔐 Risk Levels

MCP Bridge implements an optional risk level system that provides control over server execution behaviors. Risk levels help manage security and resource concerns when executing potentially sensitive MCP server operations.

### Risk Level Classification

| Level | Name | Description | Behavior |
|-------|------|-------------|----------|
| 1 | Low | Standard execution | Direct execution without confirmation |
| 2 | Medium | Requires confirmation | Client must confirm execution before processing |
| 3 | High | Docker execution required | Server runs in isolated Docker container |

### Configuring Risk Levels

Risk levels are optional for backward compatibility. You can configure risk levels in your `mcp_config.json`:

```json
{
  "mcpServers": {
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/path/to/directory"],
      "riskLevel": 2
    },
    "slack": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-slack"],
      "env": {
        "SLACK_BOT_TOKEN": "your-slack-token",
        "SLACK_TEAM_ID": "your-team-id"
      },
      "riskLevel": 1
    },
    "github": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-github"],
      "env": {
        "GITHUB_TOKEN": "your-github-token"
      },
      "riskLevel": 3,
      "docker": {
        "image": "node:18",
        "volumes": ["/tmp:/tmp"],
        "network": "host"
      }
    }
  }
}
```

### Risk Level Workflows

#### Low Risk (Level 1)
- Standard execution without additional steps
- Suitable for operations with minimal security concerns
- This is the default behavior when no risk level is specified

#### Medium Risk (Level 2)
1. Client makes a tool execution request
2. Server responds with a confirmation request containing a confirmation ID
3. Client must make a separate confirmation request to proceed
4. Only after confirmation does the server execute the operation

The MCP-Gemini Agent handles this confirmation flow automatically, prompting the user for approval when needed.

#### High Risk (Level 3)
- Server automatically runs in an isolated Docker container
- Provides environmental isolation for the MCP server process
- Requires Docker to be installed and properly configured

## 🚧 Deployment Considerations

### 🔒 Security

- Use HTTPS in production
- Add auth for sensitive operations
- Network-isolate critical services

### 📊 Scaling

- Use load balancers
- Pool high-demand servers
- Track metrics and resource pressure

## 📝 License

MIT License
